{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Shape From Shading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 0: Load the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 128, 128, 3)\n",
      "(20000, 128, 128, 3)\n",
      "(20000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "#number of ALL images \n",
    "num_all = 20000\n",
    "num_train = 18000\n",
    "num_test = 2000\n",
    "\n",
    "#import ALL color images \n",
    "color_dir = \"train/color/\"\n",
    "color = []\n",
    "for i in range(num_all):\n",
    "    img = cv2.imread(color_dir + str(i) + \".png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #resize image\n",
    "    #img = cv2.resize(img,(32, 32))\n",
    "    color.append(img)\n",
    "color = np.asarray(color)\n",
    "\n",
    "#import train masks\n",
    "mask_dir = \"train/mask/\"\n",
    "mask = []\n",
    "for i in range(num_all):\n",
    "    img = cv2.imread(mask_dir + str(i) + \".png\")\n",
    "    #resize image\n",
    "    #img = cv2.resize(img,(32, 32))\n",
    "    mask.append(img)\n",
    "mask = np.asarray(mask)\n",
    "\n",
    "#import train normal\n",
    "normal_dir = \"train/normal/\"\n",
    "normal = []\n",
    "for i in range(num_all):\n",
    "    img = cv2.imread(normal_dir + str(i) + \".png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #resize image\n",
    "    #img = cv2.resize(img,(32, 32))\n",
    "    normal.append(img)\n",
    "normal = np.asarray(normal)\n",
    "\n",
    "#train set \n",
    "train_color = color[0:num_train]\n",
    "train_mask = mask[0:num_train]\n",
    "train_normal = normal[0:num_train]\n",
    "\n",
    "#test set \n",
    "test_color = color[num_train:num_all]\n",
    "test_mask = mask[num_train:num_all]\n",
    "test_normal = normal[num_train:num_all]\n",
    "\n",
    "\n",
    "#print dimentions \n",
    "print(color.shape)\n",
    "print(mask.shape)\n",
    "print(normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def extract_hypercolumn(model, layer_indexes, instance):\n",
    "    layers = [model.layers[li].output for li in layer_indexes]\n",
    "    get_features = K.function([model.layers[0].input, K.learning_phase()], layers)\n",
    "    \n",
    "    feature_maps = get_features([instance,0])\n",
    "    hypercolumns = []\n",
    "    for convmap in feature_maps:\n",
    "        hc = []\n",
    "        for fmap in convmap[0]:\n",
    "            #fmap = sp.misc.imresize(fmap, size=(224, 224), mode=\"F\", interp='bilinear')\n",
    "            #hypercolumns.append(fmap)\n",
    "            hc.append(fmap)\n",
    "        hc = np.average(hc, axis=2)\n",
    "        hc = sp.misc.imresize(hc, size=(128, 128), mode=\"F\", interp='bilinear')\n",
    "        hypercolumns.append(hc)\n",
    "    return np.asarray(hypercolumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layers_extract = [1,2,4,5,7,8,9,11,12,13,15,16,17]\n",
    "\n",
    "x = cv2.resize(train_color[0], (224, 224))\n",
    "x = image.img_to_array(x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "hc = extract_hypercolumn(model, layers_extract, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "temp = np.zeros((128,128,13))\n",
    "for i in range(13):\n",
    "    temp[:,:,i] = hc[i,:,:]\n",
    "hc = temp \n",
    "print(hc.shape)\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(hc[:,:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_color_hpc = []\n",
    "layers_extract = [1,2,4,5,7,8,9,11,12,13,15,16,17]\n",
    "count = 0\n",
    "for col in train_color:\n",
    "    if np.mod(count,100) == 0:\n",
    "        print(count)\n",
    "    count = count + 1\n",
    "    x = cv2.resize(col, (224, 224))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    hc = extract_hypercolumn(model, layers_extract, x)\n",
    "    train_color_hpc.append(hc)\n",
    "train_color_hpc = np.asarray(train_color_hpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import theano\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import manifold\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def IIINet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    #model.add(Flatten(input_shape = (128,128,13)))\n",
    "    #model.add(Dense(131072, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(98304, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(49152, activation='softmax'))\n",
    "    #model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7e6b59cf5a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"0\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hc' is not defined"
     ]
    }
   ],
   "source": [
    "X = hc\n",
    "y = plt.imread(normal_dir + \"0\" + \".png\")\n",
    "X = np.reshape(X, -1)\n",
    "y = np.reshape(y, -1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf Graph Input\n",
    "learning_rate = 0.01\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.truncated_normal(shape = (212992,49152), name = \"weight\"))\n",
    "b = tf.Variable(tf.zeros(49152), name = 'bias')\n",
    "n_samples = tf.constant(1)\n",
    "#W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "#b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "    training_cost = sess.run(cost, feed_dict={X: X, Y: y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "estimator = KerasRegressor(build_fn=IIINet, nb_epoch=100, batch_size=1, verbose=0)\n",
    "results = cross_val_score(estimator, X, y)\n",
    "\n",
    "#model = IIINet()\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#history = model.fit(X, y, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(color[0])\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(mask[0])\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(normal[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocess Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here. Preprocessing steps could include normalization, converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_color, train_mask, train_normal = shuffle(train_color, train_mask, train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import theano\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import manifold\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), dim_ordering = 'th'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), dim_ordering = 'th'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering = 'th'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), dim_ordering = 'th'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), dim_ordering = 'th'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = VGG_16('vgg16_weights.h5')\n",
    "#model = VGG_16()\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im_original = cv2.resize(cv2.imread('madruga.jpg'), (224, 224))\n",
    "im = im_original.transpose((2,0,1))\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im_converted = cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Set up TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def IIINet(x):\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 32x32x15.\n",
    "    #filters \n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape = (5,5,1,15)))\n",
    "    conv1_b = tf.Variable(tf.zeros(15))\n",
    "    strides = [1,1,1,1]\n",
    "    padding = 'SAME'\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides, padding) + conv1_b\n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    # TODO: Pooling. Input = 32x32x15. Output = 16x16x15.\n",
    "    filter_shape = [1,2,2,1]\n",
    "    strides = [1,2,2,1]\n",
    "    padding = 'VALID'\n",
    "    conv1 = tf.nn.max_pool(conv1, filter_shape, strides, padding)\n",
    "    \n",
    "    #Layer 2: Convolutional. Input = 16x16x15. Output = 16x16x40.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape = (5,5,15,40)))\n",
    "    conv2_b = tf.Variable(tf.zeros(40))\n",
    "    strides = [1,1,1,1]\n",
    "    padding = 'SAME'\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides, padding) + conv2_b\n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # TODO: Pooling. Input = 16x16x40 Output = 8x8x40.\n",
    "    filter_shape = [1,2,2,1]\n",
    "    strides = [1,2,2,1]\n",
    "    padding = 'VALID'\n",
    "    conv2 = tf.nn.max_pool(conv2, filter_shape, strides, padding)\n",
    "                          \n",
    "                \n",
    "    # TODO: Flatten. Input = 8x8x40. Output = 2560.\n",
    "    fc0 = flatten(conv2)\n",
    "    # TODO: Layer 3: Fully Connected. Input = 2560. Output = 1500.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape = (2560,1500)))\n",
    "    fc1_b = tf.Variable(tf.zeros(1500))\n",
    "    fc1 = tf.add(tf.matmul(fc0, fc1_W), fc1_b)\n",
    "    # TODO: Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # TODO: Layer 4: Fully Connected. Input = 1500. Output = 1024.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape = (1500,1024)))\n",
    "    fc2_b = tf.Variable(tf.zeros(1024))\n",
    "    logits = tf.add(tf.matmul(fc1, fc2_W), fc2_b)\n",
    "    return logits\n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32,1))\n",
    "y = tf.placeholder(tf.int32, (None, 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "rate = 0.001\n",
    "\n",
    "logits = IIINet(x)\n",
    "#total_loss = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(x, tf.cast(y, tf.float32)))))\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "saver = tf.train.Saver()\n",
    "#loss = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(logits, tf.cast(y, tf.float32)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = num_train\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(train_color, train_normal)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            batch_x = batch_x[:,:,:,0]\n",
    "            batch_y = batch_y[:,:,:,0]\n",
    "            batch_x = np.reshape(batch_x, [-1,32,32,1])\n",
    "            batch_y = np.reshape(batch_y, [-1,1024])\n",
    "            batch_x = (batch_x / 255 - 0.5) * 2\n",
    "            batch_y = (batch_y / 255 - 0.5) * 2\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "    \n",
    "    saver.save(sess, './iiinet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    test_x = train_color[0,:,:,0]\n",
    "    test_x = np.reshape(test_x, [-1,32,32,1])\n",
    "    test_x = (test_x / 255 - 0.5) * 2\n",
    "    output = sess.run(logits, feed_dict={x: test_x})\n",
    "    output = np.reshape(output, [32,32])\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
